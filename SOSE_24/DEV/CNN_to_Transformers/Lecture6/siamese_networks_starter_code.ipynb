{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Showing images\n",
    "def imshow(img, text=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "        \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "# Plotting data\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the dataset and generate the pairs on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self,imageFolderDataset,transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "\n",
    "        #We need to approximately 50% of images to be in the same class\n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                #Look untill the same class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] == img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "\n",
    "            while True:\n",
    "                #Look untill a different class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] != img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "folder_dataset = datasets.ImageFolder(root=\"./data/faces/training/\")\n",
    "\n",
    "# Resize the images and transform to tensors\n",
    "transformation = transforms.Compose([transforms.Resize((100,100)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.5],std=[0.5])\n",
    "                                    ])\n",
    "\n",
    "# Initialize the network\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
    "                                        transform=transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple dataloader just for simple visualization\n",
    "vis_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2,\n",
    "                        batch_size=8)\n",
    "\n",
    "# Extract one batch\n",
    "example_batch = next(iter(vis_dataloader))\n",
    "\n",
    "# Example batch is a list containing 2x8 images, indexes 0 and 1, an also the label\n",
    "# If the label is 1, it means that it is not the same person, label is 0, same person in both images\n",
    "concatenated = torch.cat((example_batch[0], example_batch[1]),0)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the Siamese Neural Network\n",
    "class SiameseNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=11,stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3,stride=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Setting up the Fully Connected Layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(384, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(256,2)\n",
    "        )\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        # This function will be called for both images\n",
    "        # Its output is used to determine the similiarity\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # In this function we pass in both images and obtain both vectors\n",
    "        # which are returned\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Contrastive Loss Function\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=5.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "      # Calculate the euclidean distance and calculate the contrastive loss\n",
    "      euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "      # label = 1 means different people, label = 0 means same people  \n",
    "      loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "      return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=64)\n",
    "\n",
    "net = SiameseNetwork().cuda()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0005 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "# Iterate throught the epochs\n",
    "for epoch in range(100):\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i, (img0, img1, label) in enumerate(train_dataloader, 0):\n",
    "\n",
    "        # Send the images and labels to CUDA\n",
    "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass in the two images into the network and obtain two outputs\n",
    "        output1, output2 = net(img0, img1)\n",
    "\n",
    "        # Pass the outputs of the networks and label into the loss function\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "\n",
    "        # Calculate the backpropagation\n",
    "        loss_contrastive.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Every 10 batches print out the loss\n",
    "        if i % 10 == 0 :\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss_contrastive.item()}\\n\")\n",
    "            iteration_number += 10\n",
    "\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "\n",
    "show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
    "folder_dataset_test = datasets.ImageFolder(root=\"./data/faces/testing/\")\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
    "                                        transform=transformation)\n",
    "test_dataloader = DataLoader(siamese_dataset, num_workers=2, batch_size=1, shuffle=True)\n",
    "\n",
    "# Grab one image that we are going to test\n",
    "dataiter = iter(test_dataloader)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    # Iterate over 5 images and test them with the first image (x0)\n",
    "    x0, x1, label2 = next(dataiter)\n",
    "\n",
    "    # Concatenate the two images together\n",
    "    concatenated = torch.cat((x0, x1), 0)\n",
    "    \n",
    "    output1, output2 = net(x0.cuda(), x1.cuda())\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    imshow(torchvision.utils.make_grid(concatenated), f'Dissimilarity: {euclidean_distance.item():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline triplet generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "def triplets(folder_paths, max_triplets=20):\n",
    "    anchor_images = []\n",
    "    positive_images = []\n",
    "    negative_images = []\n",
    "\n",
    "    for person_folder in folder_paths:\n",
    "        images = [os.path.join(person_folder, img)\n",
    "                  for img in os.listdir(person_folder)]\n",
    "        num_images = len(images)\n",
    "\n",
    "        if num_images < 2:\n",
    "            continue\n",
    "\n",
    "        random.shuffle(images)\n",
    "\n",
    "        for _ in range(max(num_images-1, max_triplets)):\n",
    "            anchor_image = random.choice(images)\n",
    "\n",
    "            positive_image = random.choice([x for x in images\n",
    "                                            if x != anchor_image])\n",
    "\n",
    "            negative_folder = random.choice([x for x in folder_paths\n",
    "                                             if x != person_folder])\n",
    "            \n",
    "            \n",
    "            negative_image = random.choice([os.path.join(negative_folder, img)\n",
    "                                            for img in os.listdir(negative_folder)])\n",
    "\n",
    "            anchor_images.append(anchor_image)\n",
    "            positive_images.append(positive_image)\n",
    "            negative_images.append(negative_image)\n",
    "\n",
    "    return anchor_images, positive_images, negative_images\n",
    "\n",
    "DATASET = \"./data/faces/training/\"\n",
    "\n",
    "person_folders = [os.path.join(DATASET, folder_name)\n",
    "                  for folder_name in os.listdir(DATASET)]\n",
    "\n",
    "anchors, positives, negatives = triplets(person_folders,max_triplets=50)\n",
    "\n",
    "print(f\"Number of triplets: {len(anchors)}\")\n",
    "print(f\"Example triplet: {anchors[1]}, {positives[1]}, {negatives[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Define the dataset for TripletNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## TODO: Implement the TripletNetworkDataset\n",
    "class TripletNetworkDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        print(\"Dataset initialized\")\n",
    "    def __getitem__(self,index):\n",
    "        return None\n",
    "    def __len__(self):\n",
    "        return None\n",
    "    \n",
    "# Resize the images and transform to tensors\n",
    "transformation = transforms.Compose([transforms.Resize((100,100)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.5],std=[0.5])\n",
    "                                    ])\n",
    "\n",
    "## TODO: Initialize the dataset\n",
    "# Define the dataset\n",
    "triplet_dataset = TripletNetworkDataset()\n",
    "\n",
    "# Create a simple dataloader just for simple visualization\n",
    "vis_dataloader = DataLoader(triplet_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2,\n",
    "                        batch_size=8)\n",
    "\n",
    "# Extract one batch\n",
    "example_batch = next(iter(vis_dataloader))\n",
    "\n",
    "# Example batch is a list containing 3x8 images, indexes 0,1,3\n",
    "concatenated = torch.cat((example_batch[0], example_batch[1],example_batch[2]),0)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Implement the TripletSiameseNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_loss = nn.TripletMarginLoss(margin=1, p=2, eps=1e-7)\n",
    "train_dataloader_triplet = DataLoader(triplet_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=64)\n",
    "\n",
    "#######################################################\n",
    "## TODO: Implement the TripletNetwork\n",
    "#create the Siamese Neural Network\n",
    "class TripletSiameseNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TripletSiameseNetwork, self).__init__()\n",
    "        print(\"TripletSiameseNetwork initialized\")\n",
    "    \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "    def forward(self):\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "net = TripletSiameseNetwork().cuda()\n",
    "criterion_triplet = triplet_loss\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0005 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "# Iterate throught the epochs\n",
    "for epoch in range(100):\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i, (img0, img1, img2) in enumerate(train_dataloader_triplet, 0):\n",
    "\n",
    "        # Send the images and labels to CUDA\n",
    "        img0, img1, img2 = img0.cuda(), img1.cuda(), img2.cuda()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass in the two images into the network and obtain two outputs\n",
    "        output0, output1, output2 = net(img0, img1,img2)\n",
    "\n",
    "        # Pass the outputs of the networks and label into the loss function\n",
    "        loss_triplet = criterion_triplet(output0, output1, output2)\n",
    "\n",
    "        # Calculate the backpropagation\n",
    "        loss_triplet.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Every 10 batches print out the loss\n",
    "        if i % 10 == 0 :\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss_triplet.item()}\\n\")\n",
    "            iteration_number += 10\n",
    "\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_triplet.item())\n",
    "\n",
    "show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
    "folder_dataset_test = \"./data/faces/testing/\"\n",
    "person_folders = [os.path.join(folder_dataset_test, folder_name)\n",
    "                  for folder_name in os.listdir(folder_dataset_test)]\n",
    "test_triplets_a, test_triplets_p,test_triplets_n = triplets(person_folders)\n",
    "triplet_dataset_test = TripletNetworkDataset(test_triplets_a, test_triplets_p,test_triplets_n,\n",
    "                                        transform=transformation)\n",
    "test_dataloader = DataLoader(triplet_dataset_test, num_workers=2, batch_size=1, shuffle=True)\n",
    "\n",
    "# Create a simple dataloader just for simple visualization\n",
    "vis_dataloader1 = DataLoader(triplet_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=2,\n",
    "                        batch_size=1)\n",
    "\n",
    "\n",
    "# Grab one image that we are going to test\n",
    "dataiter = iter(test_dataloader)\n",
    "\n",
    "net.eval()\n",
    "for i in range(5):\n",
    "    # Iterate over 5 images and test them with the first image (x0)\n",
    "    x0, x1, x2 = next(dataiter)\n",
    "\n",
    "    # Concatenate the two images together\n",
    "    concatenated = torch.cat((x0, x1,x2))\n",
    "    \n",
    "    output0, output1, output2 = net(x0.cuda(), x1.cuda(),x2.cuda())\n",
    "    euclidean_distance_positive = F.pairwise_distance(output0, output1)\n",
    "    euclidean_distance_negative = F.pairwise_distance(output0, output2)\n",
    "\n",
    "   \n",
    "    imshow(torchvision.utils.make_grid(concatenated), f'Similarity positive: {euclidean_distance_positive.item():.2f} Similarity negative: {euclidean_distance_negative.item():.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MonaiLatestEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
