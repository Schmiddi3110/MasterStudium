{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8093e27a-33f6-4cd9-a47b-ea94c3d0c514",
   "metadata": {},
   "source": [
    "# Evasion Attacks and Defenses on Hugging Face Models using ART - Part 2 Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549129e5-f6f4-4995-b334-d22cb4cae76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from art.estimators.classification.hugging_face import HuggingFaceClassifierPyTorch\n",
    "from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
    "from art.defences.trainer import AdversarialTrainerMadryPGD\n",
    "from art.utils import load_dataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # <-- use the GPU if available, otherwise the CPU (slow!)\n",
    "# In case you work on a Mac with Apple Silicon or AMD GPU you can use 'mps' device.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb79189",
   "metadata": {},
   "source": [
    "## Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf2bba-efc1-4db7-8041-698105537b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use a small subset of the CIFAR-10 dataset.\n",
    "# For test and debugging runs you can even reduce this parameters to avoid long calculation times.\n",
    "SAMPLES_PER_CLASS = 100\n",
    "\n",
    "\n",
    "\n",
    "(x_train, y_train), (_, _), _, _ = load_dataset('cifar10')\n",
    "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "\n",
    "x_subset = []\n",
    "y_subset = []\n",
    "\n",
    "for c in classes:\n",
    "    indices = y_train == c\n",
    "    x_subset.append(x_train[indices][:SAMPLES_PER_CLASS])\n",
    "    y_subset.append(y_train[indices][:SAMPLES_PER_CLASS])\n",
    "\n",
    "x_subset = np.concatenate(x_subset)\n",
    "y_subset = np.concatenate(y_subset)\n",
    "\n",
    "print(f'x_subset:', x_subset.dtype, x_subset.shape)\n",
    "print(f'y_subset:', y_subset.dtype, y_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04679ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create state_dicts directory for saving models\n",
    "\n",
    "if not os.path.isdir('./state_dicts'):\n",
    "    os.mkdir('./state_dicts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1c258",
   "metadata": {},
   "source": [
    "Set model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a80e5",
   "metadata": {},
   "source": [
    "# PyTorch Image Models (timm)\n",
    "\n",
    "PyTorch Image Models (timm) is a poular repository for SOTA implementations of image models and Hugging Face is hosting many of the models and weights.\n",
    "\n",
    "We can use timm models here with the same wrapper.\n",
    "\n",
    "To run this part of the notebook we need to install the timm library\n",
    "\n",
    "`pip install timm`\n",
    "\n",
    "This notebook was ran with timm==0.9.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18de084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a small ResNet Model\n",
    "MODEL_NAME = 'resnet18.a1_in1k'\n",
    "# Later use a bigger one: \n",
    "# MODEL_NAME = 'resnet50.a1_in1k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = timm.create_model(MODEL_NAME, pretrained=True)\n",
    "upsampler = torch.nn.Upsample(scale_factor=7, mode='nearest')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "timm_model = HuggingFaceClassifierPyTorch(\n",
    "    model=model,\n",
    "    loss=loss_fn,\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=10,\n",
    "    optimizer=optimizer,\n",
    "    clip_values=(0, 1),\n",
    "    processor=upsampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e75fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=2000\n",
    "#timm_model.fit(x_subset[:limit], y_subset[:limit], nb_epochs=1)\n",
    "timm_model.fit(x_subset, y_subset, nb_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87441d",
   "metadata": {},
   "source": [
    "Takes approx. 1 min / epoch for ResNet18 on MacBook Pro...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724cb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = timm_model.predict(x_subset)\n",
    "preds = np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "timm_acc = np.mean(preds == y_subset)\n",
    "print('accuracy:', timm_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3209e",
   "metadata": {},
   "source": [
    "## Adversarial Training with ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer_resnet = AdversarialTrainerMadryPGD(\n",
    "    classifier=timm_model,\n",
    "    nb_epochs=15,\n",
    "    eps=8/255,\n",
    "    eps_step=1/255,\n",
    "    max_iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model if it already exists, otherwise train it\n",
    "\n",
    "model_checkpoint_path = './state_dicts/timm_%s_cifar_robust_model.pt' % MODEL_NAME\n",
    "if os.path.isfile(model_checkpoint_path):\n",
    "    trainer_resnet.classifier.model.load_state_dict(torch.load(model_checkpoint_path, map_location=device))\n",
    "    print('loaded model checkpoint')\n",
    "else:\n",
    "    trainer_resnet.fit(x_subset, y_subset, nb_epochs=5)\n",
    "    torch.save(trainer_resnet.classifier.model.state_dict(), model_checkpoint_path)\n",
    "    print('saved model checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499268c6",
   "metadata": {},
   "source": [
    "about 12 min per epoch (MacBookPro M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer_resnet.classifier.predict(x_subset)\n",
    "clean_preds = np.argmax(outputs, axis=1)\n",
    "clean_acc = np.mean(clean_preds == y_subset)\n",
    "print('ResNet clean accuracy:', clean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7c0c4",
   "metadata": {},
   "source": [
    "approx. 90 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load adversarial samples if they already exist, otherwise generate them\n",
    "\n",
    "adv_samples_path = './state_dicts/x_adv_robust.timm_%s_npy' % MODEL_NAME\n",
    "if os.path.isfile(adv_samples_path):\n",
    "    x_adv = np.load(adv_samples_path)\n",
    "else:\n",
    "    attacker = ProjectedGradientDescentPyTorch(trainer_resnet.classifier, eps=8/255, eps_step=1/255)\n",
    "    x_adv = attacker.generate(x_subset)\n",
    "    np.save(adv_samples_path, x_adv)\n",
    "\n",
    "outputs = trainer_resnet.classifier.predict(x_adv)\n",
    "adv_preds = np.argmax(outputs, axis=1)\n",
    "adv_acc = np.mean(adv_preds == y_subset)\n",
    "print('%s adversarial accuracy:' % MODEL_NAME, adv_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77c261",
   "metadata": {},
   "source": [
    "### Your task\n",
    "You make an observation here, which is well known in AI security: Your model suffers from being made robust... You all had basic classes in Machine Learning. Please, analyze the following aspects:\n",
    "- Visualize the images that are correcly classified and those that are wrong classified\n",
    "- Vary key hyperparameters (at least manually or a simple grid search), you can choose a hyperparameter tuning framework if you are familiar with it. \n",
    "- Vary the parameters of the adversarial training (parameters of class AdversarialTrainerMadryPGD, e.g. eps). Do you see an influence?\n",
    "- Try with ResNet50, do you see a difference? (You will need GPUs and some time for that).\n",
    "\n",
    "General hints:\n",
    "- Consider cross-reading Madry's paper from the lecutre. \n",
    "- Work in teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac06290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_images(images, true_labels, predicted_labels):\n",
    "    fig, axs = plt.subplots(2,num_per_row, figsize=(12, 6))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, (image, true_label, predicted_label) in enumerate(zip(images, true_labels, predicted_labels)):\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(f'True: {true_label}\\nPredicted: {predicted_label}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "correctly_classified_images = x_adv[adv_preds == y_subset]\n",
    "correctly_classified_labels = y_subset[adv_preds == y_subset]\n",
    "correctly_classified_predicted_labels = adv_preds[adv_preds == y_subset]\n",
    "\n",
    "wrongly_classified_images = x_adv[adv_preds != y_subset]\n",
    "wrongly_classified_labels = y_subset[adv_preds != y_subset]\n",
    "wrongly_classified_predicted_labels = adv_preds[adv_preds != y_subset]\n",
    "\n",
    "num_per_row = 8\n",
    "\n",
    "# Visualize correctly classified images\n",
    "visualize_images(correctly_classified_images, correctly_classified_labels, correctly_classified_predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
